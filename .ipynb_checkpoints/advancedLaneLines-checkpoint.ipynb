{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NeedDownloadError",
     "evalue": "Need ffmpeg exe. You can download it by calling:\n  imageio.plugins.ffmpeg.download()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNeedDownloadError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/imageio/plugins/ffmpeg.py\u001b[0m in \u001b[0;36mget_exe\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m             exe = get_remote_file('ffmpeg/' + FNAME_PER_PLATFORM[plat],\n\u001b[0;32m---> 82\u001b[0;31m                                   auto=False)\n\u001b[0m\u001b[1;32m     83\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mst_mode\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mstat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mS_IEXEC\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# executable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/imageio/core/fetching.py\u001b[0m in \u001b[0;36mget_remote_file\u001b[0;34m(fname, directory, force_download, auto)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mauto\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNeedDownloadError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNeedDownloadError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNeedDownloadError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4e44d1197e13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmoviepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meditor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVideoFileClip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHTML\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/moviepy/editor.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Clips\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mvideo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVideoFileClip\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVideoFileClip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mvideo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageSequenceClip\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageSequenceClip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mvideo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdownload_webfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/moviepy/video/io/VideoFileClip.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmoviepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvideo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVideoClip\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVideoClip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmoviepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAudioFileClip\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAudioFileClip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmoviepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClip\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/moviepy/video/VideoClip.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmoviepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0maio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mffmpeg_writer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mffmpeg_write_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mffmpeg_write_video\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mffmpeg_tools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mffmpeg_merge_video_audio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m from .io.gif_writers import (write_gif,\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/moviepy/video/io/ffmpeg_writer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmoviepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPY3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVNULL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmoviepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_setting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmoviepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mverbose_print\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/moviepy/config.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mFFMPEG_BINARY\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'ffmpeg-imageio'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mimageio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplugins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mffmpeg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_exe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mFFMPEG_BINARY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_exe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0mFFMPEG_BINARY\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'auto-detect'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/imageio/plugins/ffmpeg.py\u001b[0m in \u001b[0;36mget_exe\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mexe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mNeedDownloadError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             raise NeedDownloadError('Need ffmpeg exe. '\n\u001b[0m\u001b[1;32m     87\u001b[0m                                     \u001b[0;34m'You can download it by calling:\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                                     '  imageio.plugins.ffmpeg.download()')\n",
      "\u001b[0;31mNeedDownloadError\u001b[0m: Need ffmpeg exe. You can download it by calling:\n  imageio.plugins.ffmpeg.download()"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### image info\n",
    "img_height = 720\n",
    "img_width = 1280\n",
    "img_midpoint = img_width // 2\n",
    "img_size = (img_width, img_height)\n",
    "\n",
    "### conversions between meters and pixels (for the warped images)\n",
    "ym_per_px = 30 / (img_height)\n",
    "xm_per_px = 3.7 / (img_width / 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### camera calibration\n",
    "\n",
    "# read images\n",
    "cal_images = glob.glob(\"camera_cal/calibration*.jpg\")\n",
    "\n",
    "# initialize arrays for object points and image points\n",
    "objp = np.zeros((9*6,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9, 0:6].T.reshape(-1,2)\n",
    "\n",
    "objpoints = []\n",
    "imgpoints = []\n",
    "\n",
    "# loop through images, find chessboard corners, and add corresponding image points and object points to arrays\n",
    "for idx, fname in enumerate(cal_images):\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9, 6), None)\n",
    "    \n",
    "    if ret:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "# calibrate camera\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size, None, None)\n",
    "\n",
    "# define function to undistort images, using coefficients found from camera calibration\n",
    "def undistort_image(image):\n",
    "    undist_image = cv2.undistort(image, mtx, dist, None, mtx)\n",
    "    \n",
    "    return undist_image\n",
    "\n",
    "# show distorted and undistorted version of same image\n",
    "orig_cal_img = cv2.imread(cal_images[0])\n",
    "undist_cal_img = undistort_image(orig_cal_img)\n",
    "\n",
    "fig = plt.figure(figsize=(20, 5))\n",
    "\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax1.imshow(orig_cal_img)\n",
    "ax1.set_title(\"Original Image\", fontsize=30)\n",
    "\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "ax2.imshow(undist_cal_img)\n",
    "ax2.set_title(\"Undistorted Image\", fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### perspective transform\n",
    "\n",
    "# read and undistort images for straight road\n",
    "straight_image_paths = glob.glob(\"test_images/straight_lines*.jpg\")\n",
    "straight_images = [cv2.imread(path) for path in straight_image_paths]\n",
    "straight_images = np.array([undistort_image(img) for img in straight_images])\n",
    "\n",
    "# define source points on original images\n",
    "src_lower_left = [215, 720]\n",
    "src_upper_left = [580, 460]\n",
    "src_upper_right = [705, 460]\n",
    "src_lower_right = [1120, 720]\n",
    "\n",
    "# define destination points on warped image\n",
    "dst_lower_left = [img_width // 3, img_height]\n",
    "dst_upper_left = [img_width // 3, 0]\n",
    "dst_upper_right = [img_width * 2 // 3, 0]\n",
    "dst_lower_right = [img_width * 2 // 3, img_height]\n",
    "\n",
    "# define shapes for src and dst points\n",
    "src_pts = np.float32([src_lower_left, src_upper_left, src_upper_right, src_lower_right])\n",
    "dst_pts = np.float32([dst_lower_left, dst_upper_left, dst_upper_right, dst_lower_right])\n",
    "\n",
    "# get transform and inverse transform matrices\n",
    "M = cv2.getPerspectiveTransform(src_pts, dst_pts)\n",
    "Minv = cv2.getPerspectiveTransform(dst_pts, src_pts)\n",
    "\n",
    "# define functions to warp and unwarp images, using transform matrices\n",
    "def warp_image(image):\n",
    "    warped_image = cv2.warpPerspective(image, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "        \n",
    "    return warped_image\n",
    "\n",
    "def unwarp_image(image):\n",
    "    unwarped_image = cv2.warpPerspective(image, Minv, img_size, flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    return unwarped_image\n",
    "\n",
    "# warp straight images\n",
    "warped_straight_images = np.uint8([warp_image(img) for img in straight_images])\n",
    "\n",
    "# plot original and warped images\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "\n",
    "for i in range(2):\n",
    "    ax1 = fig.add_subplot(2, 2, 2*i+1)\n",
    "    plt.imshow(straight_images[i,:,:,::-1])\n",
    "    plt.plot(src_lower_left[0], src_lower_left[1], \"ro\")\n",
    "    plt.plot(src_upper_left[0], src_upper_left[1], \"ro\")\n",
    "    plt.plot(src_upper_right[0], src_upper_right[1], \"ro\")\n",
    "    plt.plot(src_lower_right[0], src_lower_right[1], \"ro\")\n",
    "    plt.xlim([0, img_width])\n",
    "    plt.ylim([img_height, 0])\n",
    "    \n",
    "    ax2 = fig.add_subplot(2, 2, 2*i+2)\n",
    "    plt.imshow(warped_straight_images[i,:,:,::-1])\n",
    "    plt.plot(dst_lower_left[0], dst_lower_left[1], \"ro\")\n",
    "    plt.plot(dst_upper_left[0], dst_upper_left[1], \"ro\")\n",
    "    plt.plot(dst_upper_right[0], dst_upper_right[1], \"ro\")\n",
    "    plt.plot(dst_lower_right[0], dst_lower_right[1], \"ro\")\n",
    "    plt.xlim([0, img_width])\n",
    "    plt.ylim([img_height, 0])\n",
    "    \n",
    "    if i == 0:\n",
    "        ax1.set_title(\"Original Images\", fontsize=30)\n",
    "        ax2.set_title(\"Warped Images\", fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### process images\n",
    "\n",
    "# read and undistort test images\n",
    "test_image_paths = glob.glob(\"test_images/test*.jpg\")\n",
    "test_images = [cv2.imread(path) for path in test_image_paths]\n",
    "test_images = np.array([undistort_image(img) for img in test_images])\n",
    "\n",
    "# define function for processing images\n",
    "def process(image):\n",
    "    '''\n",
    "    Takes in a BGR image, converts it to YUV, and uses two thresholds to identify lane lines:\n",
    "    To find the white lines, it thresholds the Y channel at > 200\n",
    "    To find the yellow lines, it subtracts the V channel from the U channel, and thresholds the result at > 30\n",
    "    '''\n",
    "    \n",
    "    # convert BGR image to YUV\n",
    "    yuv_img = cv2.cvtColor(image, cv2.COLOR_BGR2YUV)\n",
    "    \n",
    "    # take individual channels\n",
    "    y_channel = yuv_img[:,:,0]\n",
    "    u_channel = yuv_img[:,:,1]\n",
    "    v_channel = yuv_img[:,:,2]\n",
    "\n",
    "    # define image, y_binary, that is equal to 1 where y_channel meets the threshold, and 0 elsewhere\n",
    "    y_binary = np.zeros_like(y_channel)\n",
    "    y_binary[y_channel > 200] = 1\n",
    "    \n",
    "    # find difference between U and V channels\n",
    "    u_v_diff = u_channel.astype(np.int16) - v_channel.astype(np.int16)\n",
    "    \n",
    "    # define image, u_v_diff_binary, that is equal to 1 where u_v_diff meets the threshold, and 0 elsewhere\n",
    "    u_v_diff_binary = np.zeros_like(u_v_diff)\n",
    "    u_v_diff_binary[u_v_diff > 30] = 1\n",
    "    u_v_diff_binary = np.uint8(u_v_diff_binary)\n",
    "    \n",
    "    # created combined binary image that is equal to 1 where either condition is met\n",
    "    combined_binary = np.zeros_like(y_channel)\n",
    "    combined_binary[((u_v_diff_binary == 1) | (y_binary == 1))] = 1\n",
    "    \n",
    "    return combined_binary\n",
    "\n",
    "processed_images = np.uint8([process(img) for img in test_images])\n",
    "\n",
    "# plot original and processed images\n",
    "fig = plt.figure(figsize=(20, 30))\n",
    "\n",
    "for i in range(6):\n",
    "    ax1 = fig.add_subplot(6, 2, 2*i+1)\n",
    "    plt.imshow(test_images[i,:,:,::-1])\n",
    "    plt.xlim([0, img_width])\n",
    "    plt.ylim([img_height, 0])\n",
    "    \n",
    "    ax2 = fig.add_subplot(6, 2, 2*i+2)\n",
    "    plt.imshow(processed_images[i], cmap=\"gray\")\n",
    "    plt.xlim([0, img_width])\n",
    "    plt.ylim([img_height, 0])\n",
    "    \n",
    "    if i == 0:\n",
    "        ax1.set_title(\"Original Images\", fontsize=30)\n",
    "        ax2.set_title(\"Binary Images\", fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### region mask for warped image\n",
    "def region_mask(image):\n",
    "    '''\n",
    "    Takes and image and makes all pixels near the lateral edges black, to remove noise\n",
    "    '''\n",
    "    masked_image = np.copy(image)\n",
    "    left_margin = 300\n",
    "    right_margin = 300\n",
    "    \n",
    "    masked_image[:,0:left_margin] = 0\n",
    "    masked_image[:,img_width-right_margin:] = 0\n",
    "    \n",
    "    return masked_image\n",
    "\n",
    "warped_images = np.uint8([warp_image(img) for img in processed_images])\n",
    "masked_images = np.uint8([region_mask(img) for img in warped_images])\n",
    "\n",
    "# display binary and warped images\n",
    "fig = plt.figure(figsize=(20, 30))\n",
    "\n",
    "for i in range(6):\n",
    "    ax1 = fig.add_subplot(6, 2, 2*i+1)\n",
    "    plt.imshow(processed_images[i], cmap=\"gray\")\n",
    "    plt.xlim([0, img_width])\n",
    "    plt.ylim([img_height, 0])\n",
    "    \n",
    "    ax2 = fig.add_subplot(6, 2, 2*i+2)\n",
    "    plt.imshow(masked_images[i], cmap=\"gray\")\n",
    "    plt.xlim([0, img_width])\n",
    "    plt.ylim([img_height, 0])\n",
    "    \n",
    "    if i == 0:\n",
    "        ax1.set_title(\"Binary Images\", fontsize=30)\n",
    "        ax2.set_title(\"Warped Images\", fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to find histogram for columns in lower half of image\n",
    "def find_histogram(binary_warped):\n",
    "    histogram = np.sum(binary_warped[img_height // 2:,:], axis=0)\n",
    "    \n",
    "    return histogram\n",
    "\n",
    "# plot warped images and histograms - peaks on histograms correlate with approximate base of lanes\n",
    "fig = plt.figure(figsize=(20, 30))\n",
    "\n",
    "for i in range(6):\n",
    "    ax1 = fig.add_subplot(6, 2, 2*i+1)\n",
    "    plt.imshow(masked_images[i], cmap=\"gray\")\n",
    "    plt.xlim([0, img_width])\n",
    "    plt.ylim([img_height, 0])\n",
    "    \n",
    "    ax2 = fig.add_subplot(6, 2, 2*i+2)\n",
    "    histogram = find_histogram(masked_images[i])\n",
    "    plt.plot(histogram)\n",
    "    plt.xlim([0, img_width])\n",
    "    plt.ylim([0, np.max(histogram)])\n",
    "    \n",
    "    if i == 0:\n",
    "        ax1.set_title(\"Warped Images\", fontsize=30)\n",
    "        ax2.set_title(\"Histograms\", fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### find the lane lines\n",
    "def find_lane_lines_windows(binary_warped):\n",
    "    '''\n",
    "    function takes in a warped binary image, and finds the points in the\n",
    "    left and right lanes using a moving windows method\n",
    "    '''\n",
    "    # define image to show highlights on lane lines\n",
    "    highlighted_binary_warped = np.dstack((binary_warped,)*3) * 255\n",
    "    \n",
    "    # find histogram peaks to and use those to find the base of the lanes (where to center the first windows)\n",
    "    histogram = find_histogram(binary_warped)\n",
    "    left_win_center = np.argmax(histogram[:img_midpoint])\n",
    "    right_win_center = np.argmax(histogram[img_midpoint:]) + img_midpoint\n",
    "\n",
    "    # set number of windows and window height\n",
    "    num_windows = 9\n",
    "    window_height = img_height // num_windows\n",
    "    \n",
    "    # set width of window\n",
    "    margin = 100\n",
    "    \n",
    "    # min number of lane points need to move center of next window \n",
    "    minpix = 50\n",
    "    \n",
    "    # find indices of all white points\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    \n",
    "    # initialize arrays for points in both lanes\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "    \n",
    "    for win in range(num_windows):\n",
    "        # define boundaries of windows\n",
    "        upper_bound = img_height - win * window_height\n",
    "        lower_bound = upper_bound - window_height\n",
    "        \n",
    "        left_lane_left_bound = left_win_center - margin\n",
    "        left_lane_right_bound = left_win_center + margin\n",
    "        \n",
    "        right_lane_left_bound = right_win_center - margin\n",
    "        right_lane_right_bound = right_win_center + margin\n",
    "        \n",
    "        # draw windows\n",
    "        cv2.rectangle(highlighted_binary_warped,(left_lane_left_bound,lower_bound),(left_lane_right_bound,upper_bound),(0,255,0), 2) \n",
    "        cv2.rectangle(highlighted_binary_warped,(right_lane_left_bound,lower_bound),(right_lane_right_bound,upper_bound),(0,255,0), 2) \n",
    "        \n",
    "        # find all indices of points in nonzero arrays that fall within the window\n",
    "        left_win_inds = ((nonzerox >= left_lane_left_bound)\n",
    "                            & (nonzerox <= left_lane_right_bound)\n",
    "                            & (nonzeroy >= lower_bound)\n",
    "                            & (nonzeroy <= upper_bound)).nonzero()[0]\n",
    "        \n",
    "        right_win_inds = ((nonzerox >= right_lane_left_bound)\n",
    "                            & (nonzerox <= right_lane_right_bound)\n",
    "                            & (nonzeroy >= lower_bound)\n",
    "                            & (nonzeroy <= upper_bound)).nonzero()[0]\n",
    "        \n",
    "        left_lane_inds.append(left_win_inds)\n",
    "        right_lane_inds.append(right_win_inds)\n",
    "        \n",
    "        # if enough points are found, move the center of the next window to the mean of this one\n",
    "        if len(left_win_inds) > minpix:\n",
    "            left_win_center = np.mean(nonzerox[left_win_inds]).astype(np.int)\n",
    "        if len(right_win_inds) > minpix:\n",
    "            right_win_center = np.mean(nonzerox[right_win_inds]).astype(np.int)\n",
    "\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    \n",
    "    # find indices for points in the lanes\n",
    "    left_lane_x = nonzerox[left_lane_inds]\n",
    "    left_lane_y = nonzeroy[left_lane_inds]\n",
    "    \n",
    "    right_lane_x = nonzerox[right_lane_inds]\n",
    "    right_lane_y = nonzeroy[right_lane_inds]\n",
    "    \n",
    "    # set the color of the left lane to red, and the right lane to blue\n",
    "    highlighted_binary_warped[left_lane_y, left_lane_x] = [255, 0, 0]\n",
    "    highlighted_binary_warped[right_lane_y, right_lane_x] = [0, 0, 255]\n",
    "    \n",
    "    # fit second order polynomials to lanes in pixels\n",
    "    left_lane_coeff_px = np.polyfit(left_lane_y, left_lane_x, 2)\n",
    "    right_lane_coeff_px = np.polyfit(right_lane_y, right_lane_x, 2)\n",
    "    \n",
    "    # convert pixel distances and fit second orger polynomials to lanes in meters\n",
    "    left_lane_coeff_m = np.polyfit(left_lane_y * ym_per_px, left_lane_x * xm_per_px, 2)\n",
    "    right_lane_coeff_m = np.polyfit(right_lane_y * ym_per_px, right_lane_x * xm_per_px, 2)\n",
    "    \n",
    "    return highlighted_binary_warped, left_lane_coeff_px, right_lane_coeff_px, left_lane_coeff_m, right_lane_coeff_m\n",
    "\n",
    "# plot warped and highlighted images\n",
    "fig = plt.figure(figsize=(20, 30))\n",
    "\n",
    "for i in range(6):\n",
    "    masked_image = masked_images[i]\n",
    "    \n",
    "    ax1 = fig.add_subplot(6, 2, 2*i+1)\n",
    "    plt.imshow(masked_image, cmap=\"gray\")\n",
    "    \n",
    "    highlighted_binary_warped, left_lane_coeff_px, right_lane_coeff_px, left_lane_coeff_m, right_lane_coeff_m = find_lane_lines_windows(masked_image)\n",
    "\n",
    "    plot_y = np.linspace(0, img_height, img_height+1)\n",
    "    left_plot_x = left_lane_coeff_px[0] * plot_y**2 + left_lane_coeff_px[1] * plot_y + left_lane_coeff_px[2]\n",
    "    right_plot_x = right_lane_coeff_px[0] * plot_y**2 + right_lane_coeff_px[1] * plot_y + right_lane_coeff_px[2]\n",
    "    \n",
    "    ax2 = fig.add_subplot(6, 2, 2*i+2)\n",
    "    plt.imshow(highlighted_binary_warped)\n",
    "    plt.plot(left_plot_x, plot_y, color=\"yellow\")\n",
    "    plt.plot(right_plot_x, plot_y, color=\"yellow\")\n",
    "    plt.xlim(0, img_width)\n",
    "    plt.ylim(img_height, 0)\n",
    "    \n",
    "    if i == 0:\n",
    "        ax1.set_title(\"Warped Binary Images\", fontsize=30)\n",
    "        ax2.set_title(\"Highlighted Images\", fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# highlight the lane on the original image\n",
    "def fill_lane(orig_image, left_lane_coeff_px, right_lane_coeff_px):\n",
    "    '''\n",
    "    Takes in an image and the coefficients for the left and right lane polynomials,\n",
    "    and highlights the lane on the image\n",
    "    '''\n",
    "    # blank image\n",
    "    fill_image = np.zeros_like(orig_image)\n",
    "\n",
    "    # find points on lane best-fit curves\n",
    "    plot_y = np.linspace(0, img_height, img_height+1)\n",
    "    left_plot_x = left_lane_coeff_px[0] * plot_y**2 + left_lane_coeff_px[1] * plot_y + left_lane_coeff_px[2]\n",
    "    right_plot_x = right_lane_coeff_px[0] * plot_y**2 + right_lane_coeff_px[1] * plot_y + right_lane_coeff_px[2]\n",
    "    \n",
    "    # use points to define a polygon to fill in\n",
    "    left_poly_points = np.vstack((left_plot_x, plot_y)).T\n",
    "    right_poly_points = np.vstack((right_plot_x, plot_y)).T\n",
    "    right_poly_points = np.flipud(right_poly_points)\n",
    "    \n",
    "    poly_points = np.vstack((left_poly_points, right_poly_points))\n",
    "    poly_points = np.expand_dims(poly_points, axis=0).astype(np.int_)\n",
    "\n",
    "    # fill in between the lane curves in green\n",
    "    cv2.fillPoly(fill_image, poly_points, (0, 255, 0))\n",
    "    \n",
    "    # unwarp the filled image\n",
    "    fill_image = unwarp_image(fill_image)\n",
    "    \n",
    "    # overlay the filled lane image on top of the original images\n",
    "    fill_lane_image = cv2.addWeighted(orig_image, 1, fill_image, 0.3, 0)\n",
    "\n",
    "    return fill_lane_image\n",
    "\n",
    "# show filled lane\n",
    "filled_lane = fill_lane(test_images[5,:,:,::-1], left_lane_coeff_px, right_lane_coeff_px)\n",
    "fig = plt.figure(figsize=(20, 40))\n",
    "plt.imshow(filled_lane)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def curve_radius(left_lane_coeff_m, right_lane_coeff_m):\n",
    "    '''\n",
    "    Takes in the coefficients for the polynomials of the lane (in meters) and calculates the curve radius of the lane\n",
    "    '''\n",
    "    ym = img_height * ym_per_px\n",
    "\n",
    "    left_curve_rad_m = (1 + (2 * left_lane_coeff_m[0] * ym + left_lane_coeff_m[1])**2)**1.5 / np.absolute(2 * left_lane_coeff_m[0])\n",
    "    right_curve_rad_m = (1 + (2 * right_lane_coeff_m[0] * ym + right_lane_coeff_m[1])**2)**1.5 / np.absolute(2 * right_lane_coeff_m[0])\n",
    "    \n",
    "    curve_radius_m = (left_curve_rad_m + right_curve_rad_m) / 2\n",
    "    \n",
    "    return curve_radius_m\n",
    "\n",
    "def off_center(left_lane_coeff_px, right_lane_coeff_px):\n",
    "    '''\n",
    "    Takes in the coefficients for the polynomials for the lanes (in pixels) and calculates how far off center\n",
    "    the car is\n",
    "    '''\n",
    "    y = img_height\n",
    "    leftx = left_lane_coeff_px[0] * y**2 + left_lane_coeff_px[1] * y + left_lane_coeff_px[2]\n",
    "    rightx = right_lane_coeff_px[0] * y**2 + right_lane_coeff_px[1] * y + right_lane_coeff_px[2]\n",
    "    \n",
    "    lane_midpoint = (leftx + rightx) / 2\n",
    "    off_center_px = img_midpoint - lane_midpoint\n",
    "    \n",
    "    off_center_m = off_center_px * xm_per_px\n",
    "    \n",
    "    return off_center_m\n",
    "\n",
    "def add_stats(image, curve_radius_m, off_center_m):\n",
    "    '''\n",
    "    Add the curve radius and off center distance to the image\n",
    "    '''\n",
    "    curve_radius_text = \"Curve radius: {} m\".format(int(curve_radius_m))\n",
    "    off_center_text = \"Off center: {:.2f} m\".format(off_center_m)\n",
    "    \n",
    "    cv2.putText(image, curve_radius_text, (200,100), cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 3)\n",
    "    cv2.putText(image,off_center_text, (200,200), cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 3)\n",
    "    \n",
    "    return image\n",
    "\n",
    "# show image with curve radius and off center distance\n",
    "radius = curve_radius(left_lane_coeff_m, right_lane_coeff_m)\n",
    "off_center_pos = off_center(left_lane_coeff_px, right_lane_coeff_px)\n",
    "text_image = add_stats(filled_lane, radius, off_center_pos)\n",
    "\n",
    "fig = plt.figure(figsize=(20, 40))\n",
    "plt.imshow(text_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "curve_radii = []\n",
    "\n",
    "### pipeline\n",
    "def pipeline(image):\n",
    "    '''\n",
    "    Pipeline to take in RGB image and go through steps define above\n",
    "    '''\n",
    "    # convert rgb to bgr\n",
    "    bgr_img = image[:,:,::-1]\n",
    "    \n",
    "    # undistort image\n",
    "    undist_image = undistort_image(bgr_img)\n",
    "    \n",
    "    # process image\n",
    "    processed_image = process(undist_image)\n",
    "    \n",
    "    # warp image\n",
    "    warped_image = warp_image(processed_image)\n",
    "    \n",
    "    # mask the warped image\n",
    "    masked_image = region_mask(warped_image)\n",
    "    \n",
    "    # find the polynomial coefficients for the best fit curves for the lane lines\n",
    "    highlighted_binary_warped, left_lane_coeff_px, right_lane_coeff_px, left_lane_coeff_m, right_lane_coeff_m = find_lane_lines_windows(masked_image)\n",
    "    \n",
    "    # calculate curve radius\n",
    "    curve_radius_m = curve_radius(left_lane_coeff_m, right_lane_coeff_m)\n",
    "    \n",
    "    # remove outliers, anything else is appended to array\n",
    "    if curve_radius_m < 5000 and curve_radius_m > 200:\n",
    "        curve_radii.append(curve_radius_m)\n",
    "    \n",
    "    # take moving average of last 20 measurements to smooth out noise in curve radius\n",
    "    mean_radius = np.mean(curve_radii[-20:])\n",
    "    \n",
    "    # calculate off center distance\n",
    "    off_center_m = off_center(left_lane_coeff_px, right_lane_coeff_px)\n",
    "    \n",
    "    # fill lane\n",
    "    filled_lane = fill_lane(undist_image[:,:,::-1], left_lane_coeff_px, right_lane_coeff_px)\n",
    "    \n",
    "    # add stats\n",
    "    output = add_stats(filled_lane, mean_radius, off_center_m)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_video = 'output_video.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "output_clip = clip1.fl_image(pipeline) #NOTE: this function expects color images!!\n",
    "%time output_clip.write_videofile(output_video, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format('output_video.mp4'))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
